{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción de Potabilidad del Agua\n",
    "\n",
    "En esta ocasión se busca desarrollar un proceso de GridSearch con el fin de buscar los mejores hiperparámetros de distintos modelos dentro de un rango de valores definidos por nosotros mismos. Igualmente, se busca que usted aplique y comprenda los siguientes modelos:\n",
    "\n",
    "- Árboles de decisión\n",
    "- Bosques de decisión\n",
    "- AdaBoost\n",
    "- XGBoost\n",
    "- Bagging\n",
    "\n",
    "Se sugiere fuertemente leer la documentación entregada en los artículos de los links.\n",
    "\n",
    "Debe completar las celdas vacías y seguir las instrucciones anotadas en el cuaderno. La fecha límite de entrega es el día **8 de noviembre** y se realizará a través de Bloque Neón."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-553b766018e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOrdinalEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRobustScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler, RobustScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lectura de CSV y borrado de filas incompletas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('waterPotability/water_potability.csv').dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gráfica de proporción de clases. A continuación puede observar una desproporción entre los datos, por lo que se está lidiando con un problema desbalanceado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Potability'].value_counts().plot(kind='pie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manejo de Datos Desbalanceados: Remuestreo\n",
    "\n",
    "Utilizaremos la función `resample` de SciKit-Learn para remuestrear algunas muestras entre la clase '1'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "zero  = df[df['Potability']==0]   # clase 0\n",
    "one = df[df['Potability']==1]  # clase 1\n",
    "\n",
    "df_minority_upsampled = resample(one, replace = True, n_samples = 1200)\n",
    "df = pd.concat([zero, df_minority_upsampled])\n",
    "\n",
    "df = shuffle(df) # shuffling so that there is particular sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Potability'].value_counts().plot(kind='pie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Potability'], axis = 1)\n",
    "y = df['Potability']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1: Prueba de Modelos y GridSearch/RandomizedSearch\n",
    "\n",
    "A continuación, realizaremos un procedimiento de búsqueda del mejor modelo y sus correspondientes hiperparámetros. Estos procedimientos se conocen como GridSearch/RandomizedSearch. Puede encontrar más información en los siguientes enlaces:\n",
    "\n",
    "- [GridSearch SciKit-Learn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "- [RandomizedSearch SciKit-Learn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "- [GridSearchCV](https://www.mygreatlearning.com/blog/gridsearchcv/)\n",
    "- [Medium Article: GridSearch & RandomizedSearch](https://towardsdatascience.com/machine-learning-gridsearchcv-randomizedsearchcv-d36b89231b10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partición de datos de prueba/entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = # Utilice la función train_test_split #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1A\n",
    "\n",
    "### Definición de Parámetros de GridSearch/RandomizedSearch\n",
    "\n",
    "Basado en la documentación de las funciones, defina los siguientes parámetros para los casos:\n",
    "\n",
    "- GridSearch:\n",
    "    - Árbol de Decisión (GridSearch):\n",
    "        - 'criterion': 'gini' y 'entropy'\n",
    "        - 'max_depth': vector de valores enteros entre 1 y 50\n",
    "        - 'min_samples_leaf': 10 valores seleccionados por usted entre 1 y 100\n",
    "    \n",
    "    - Random Forest (GridSearch):\n",
    "        - 'n_estimators': 4 valores seleccionados por usted entre 100 y 500\n",
    "        - 'min_samples_leaf': 3 valores seleccionados por usted entre 2 y 30\n",
    "        \n",
    "    - AdaBoost (GridSearch):\n",
    "        - 'n_estimators': 6 valores seleccionados por usted entre 50 y 600\n",
    "        - 'learning_rate': 5 valores de tasas de aprendizaje entre 0 y 1\n",
    "        \n",
    "    - XGBoost (RandomizedSearch):\n",
    "        - 'n_estimators': 8 valores seleccionados por usted entre 50 y 600\n",
    "        - 'learning_rate': 5 valores de tasas de aprendizaje entre 0 y 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Búsqueda de Hiperparámetros\n",
    "\n",
    "lr = LogisticRegression(random_state=42)\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "ada = AdaBoostClassifier()\n",
    "\n",
    "xgb = XGBClassifier(eval_metric = 'logloss', use_label_encoder=False)\n",
    "\n",
    "#Árbol de Decisión\n",
    "para_dt = { # Diccionario con parámetros GridSearch/RandomizedSearch # }\n",
    "grid_dt = GridSearchCV(dt, param_grid=para_dt, cv=5)\n",
    "\n",
    "#Random Forest\n",
    "#n_estimators: número de árboles en el bosque.\n",
    "params_rf = { # Diccionario con parámetros GridSearch/RandomizedSearch # }\n",
    "grid_rf = GridSearchCV(rf, param_grid=params_rf, cv=5)\n",
    "\n",
    "#AdaBoost\n",
    "params_ada = { # Diccionario con parámetros GridSearch/RandomizedSearch # }\n",
    "grid_ada =  GridSearchCV(ada, param_grid=params_ada, cv=5)\n",
    "\n",
    "#XGBoost\n",
    "params_xgb = { # Diccionario con parámetros GridSearch/RandomizedSearch # }\n",
    "rs_xgb =  RandomizedSearchCV(xgb, param_distributions=params_xgb, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Búsqueda de Hiperparámetros\n",
    "\n",
    "A continuación se debe realizar el proceso de GridSearch. Esta operación puede tardar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_dt.fit(X_train, y_train)\n",
    "grid_rf.fit(X_train, y_train)\n",
    "grid_ada.fit(X_train, y_train)\n",
    "rs_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mejores parámetros Árbol de Decisión:\", grid_dt.best_params_)\n",
    "print(\"Mejores parámetros Random Forest:\", grid_rf.best_params_)\n",
    "print(\"Mejores parámetros AdaBoost:\", grid_ada.best_params_)\n",
    "print(\"Mejores parámetros XGBoost:\", rs_xgb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_dt.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1B\n",
    "\n",
    "### Boosting & Bagging\n",
    "\n",
    "Para este caso utilice 100 clasificadores de Árbol de Decisión con los mejores parámetros obtenidos a partir del GridSearch realizado anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosting & Bagging\n",
    "bagging = BaggingClassifier( # Parámetros Bagging # )\n",
    "bagging.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas de Evaluación\n",
    "\n",
    "A continuación podrá observar un resumen con las precisiones de cada modelo y posteriormente su representación gráfica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [('Regresión Logística', lr),\n",
    "               ('Árbol de Decisión', dt), ('Random Forest', rf), ('AdaBoost', ada),\n",
    "               ('Bagging', bagging), ('XGBoost', xgb)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "classifier_names = []\n",
    "classifier_acc = []\n",
    "for classifier_name, classifier in classifiers:\n",
    " \n",
    "    # Ajuste para datos de entrenamiento\n",
    "    classifier.fit(X_train, y_train)    \n",
    "\n",
    "    # Predicciones\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "\n",
    "    # Evaluación del clasificador\n",
    "    print('{:s} : {:.2f}'.format(classifier_name, accuracy))\n",
    "    classifier_names.append(classifier_name)\n",
    "    classifier_acc.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados Preliminares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.bar(classifier_names, classifier_acc, width=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2\n",
    "\n",
    "### Análisis de Resultados\n",
    "\n",
    "Ahora usted utilizará la función `classication_report` para determinar qué clasificador se ajusta más a los resultados buscados, teniendo en cuenta el contexto del problema y la simplicidad de cada modelo.\n",
    "\n",
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred_rf= rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árbol de Decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dt = dt.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = xgb.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging de Árboles de Decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bagging = bagging.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_bagging))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "Concluya a partir de los resultados obtenidos y la documentación leída sobre los métodos utilizados y las diferencias entre sus distintos rendimientos."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3e051969e02c0bebdc06d6f733c19febbd2aa470026e8181eb3693abf7eda8d5"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('proyectoGrado': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
